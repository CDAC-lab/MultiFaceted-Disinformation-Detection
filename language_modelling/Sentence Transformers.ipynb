{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31464,"status":"ok","timestamp":1640525472220,"user":{"displayName":"Srikandabala Kogul","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjJ7_wrqRECyV89KjY0M4usgytHh_ss4LSxI_aw3g=s64","userId":"12354510259357034369"},"user_tz":-330},"id":"Lxk2SvH6Yv1H","outputId":"b6d98c04-7546-43fa-9f4c-ccfaad2e1b00"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[K     |████████████████████████████████| 3.4 MB 5.4 MB/s \n","\u001b[K     |████████████████████████████████| 596 kB 46.7 MB/s \n","\u001b[K     |████████████████████████████████| 61 kB 490 kB/s \n","\u001b[K     |████████████████████████████████| 3.3 MB 41.4 MB/s \n","\u001b[K     |████████████████████████████████| 895 kB 48.6 MB/s \n","\u001b[K     |████████████████████████████████| 646 kB 5.3 MB/s \n","\u001b[?25h  Building wheel for annoy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for pandarallel (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["! pip install -U transformers -q\n","! pip install -U annoy -q\n","! pip install psutil -q\n","! pip install pandarallel -q"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xcg1DBa8ps0g"},"outputs":[],"source":["import psutil, re, torch\n","from pandarallel.utils import progress_bars\n","from pandarallel import pandarallel\n","from transformers import AutoTokenizer, AutoModel, DistilBertTokenizerFast\n","import pandas as pd\n","from annoy import AnnoyIndex\n","from tqdm.notebook import trange, tqdm\n","from sklearn.metrics import classification_report"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":60,"status":"ok","timestamp":1640440691545,"user":{"displayName":"Srikandabala Kogul","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjJ7_wrqRECyV89KjY0M4usgytHh_ss4LSxI_aw3g=s64","userId":"12354510259357034369"},"user_tz":-330},"id":"mMcnLXWrpjh_","outputId":"caaa7cc3-41f3-4de1-9dac-0c31fa624b4d"},"outputs":[{"name":"stdout","output_type":"stream","text":["INFO: Pandarallel will run on 2 workers.\n","INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"]}],"source":["workers = psutil.cpu_count()\n","\n","progress_bars.is_notebook_lab = lambda : True\n","\n","pandarallel.initialize(progress_bar=True, nb_workers=workers, use_memory_fs=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":217,"referenced_widgets":["4921d37bcbf14127aff575e0d642daae","b5f74b2090d34621ab53827b3a03c505","57db02c3b106477c9bfd367699247644","47582eb03c714d31a68a0bef22754120","063ee31f819e4bfdb4a5b99897bda37e","1d173e688bd54e888e3ad1824cfd3df0","5cf2f148ca414b3a8c0f0b35b6f8721a","2b218c33cffe430ebb20d9194caab514","4230c72eb0474f3e937096eeb86b253a","88d276ebc8814112a18da7b025ae97af","5c359d5782e446ba8868b7efe5076e66","12fa01696c7b4146828bd1d2fc5d65c2","9357739c008d41ebbb9c2b9468061405","9b834fafb7904e3f9faa28952852d066","1bf0d0f3c9964aeca517449dbfbe8f46","537d8c701b4543b3ab45500f100e1b34","3e8a6782c3c94e579d89ac2e0a4be65c","f4df98ce3bf543958a7d0075c79eaf17","04c762177b33444ab16cc51d2b1f08c9","6b0947b0384f46f580d5f0b49ef02c56","65fcc9087db04bd4be3c9f22800721c8","d748e769064b4c80b71d4ca246c9502e","89147d52186342a998836fa3ff23f20f","d75f702159ab4e78a357f7de1ae7c628","10f4b5559ab44974a2b76afd8883c2e8","c6d9181e20ef42ddbd779042cad07ef4","c1991ad9f4d740f5b6aea099ceaf06c7","fe11bc0d55de48e7a7450832291116bb","280f1e4471964b1abad6fe9408c58d63","b3ab885b70b541ab9ba05a3e73fea16f","55b5dcfdb21e417fa79131332fb062bc","cef7f46cf51d4397bbec8ad9e8391e59","bbe23adb72584c528a044540ad2fb986","2eda9fe5365d40a3a007495da6467736","048a9993dc7f4bb1bf962587aeced61a","a21acaf5b9954b17aa6ffcf740859353","e3488b85d8d246f49ef0f91dc8c892ae","8addda51ca0a42ed8670d2b3d2b30113","6233f604186541b8b4fee1a528d0c76b","cbe6abf372c64e2ba975888d3b163ba4","cdd0a42bc2d44d15a060bce6ec265882","4bfa4b0141124e4290ebaced6a61a43c","81b03fd950f44a648b382107e17c9aa8","5440388945444d728060ea090cc04613"]},"executionInfo":{"elapsed":28598,"status":"ok","timestamp":1640440720089,"user":{"displayName":"Srikandabala Kogul","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjJ7_wrqRECyV89KjY0M4usgytHh_ss4LSxI_aw3g=s64","userId":"12354510259357034369"},"user_tz":-330},"id":"wfVD-6B6JgHm","outputId":"b64b44d2-4837-4734-c72a-3c65f26590c3"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4921d37bcbf14127aff575e0d642daae","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"12fa01696c7b4146828bd1d2fc5d65c2","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"89147d52186342a998836fa3ff23f20f","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2eda9fe5365d40a3a007495da6467736","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at /content/drive/Shareddrives/[FYP] Fake News Detection/Kogul_Language_Modelling/Fine tuning WELFake/Fine-tuned Model Improved were not used when initializing DistilBertModel: ['classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["EMBEDDING_RANGE = 200\n","\n","def lower(text):\n","  return text.lower()\n","\n","# remove urls\n","def remove_urls(text):\n","    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n","    return url_pattern.sub(r'', text)\n","\n","def remove_nonascii(sent):\n","  return \"\".join([i for i in sent if i.isascii()])\n","\n","def remove_punctuations(text):\n","  res = re.sub(r'[^\\w\\s]', '', text)\n","  return res\n","\n","def remove_num(text):\n","  return \"\".join([c for c in text if not c.isdigit()])\n","\n","# remove multiple spaces\n","def remove_mul_space(text):\n","  return \" \".join(text.split())\n","\n","def clean(text):\n","  \n","  text = lower(text)\n","  text = remove_urls(text)\n","  text = remove_nonascii(text)\n","  text = remove_punctuations(text)\n","  text = remove_num(text)\n","  text = remove_mul_space(text)\n","\n","  return text\n","\n","def multiply(x,y):\n","  return x/y\n","\n","def convert_label(label):\n","  if label in ['true', 'mostly-true', 'half-true', 'real', 'Real', 0, 'REAL']:\n","    return 0\n","  if label in ['false', 'pants-fire', 'barely-true', 'fake', 'Fake', 1, 'FAKE']:\n","    return 1\n","\n","device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n","\n","# Mean Pooling - Take attention mask into account for correct averaging\n","def mean_pooling(model_output, attention_mask):\n","    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n","    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n","    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n","\n","# Load model from HuggingFace Hub\n","tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n","model = AutoModel.from_pretrained(r\"/content/drive/Shareddrives/[FYP] Fake News Detection/Kogul_Language_Modelling/Fine tuning WELFake/Fine-tuned Model Improved\")\n","model = model.to(device)\n","\n","# Generate Embeddings - This function returns the embeddings of all the texts\n","def generate_embeddings(sentences, model, tokenizer):\n","\n","  encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt').to(device)\n","\n","  with torch.no_grad():\n","    model_output = model(**encoded_input)\n","\n","  sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n","\n","  return sentence_embeddings.detach().cpu().numpy().tolist()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2080,"status":"ok","timestamp":1640440722111,"user":{"displayName":"Srikandabala Kogul","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjJ7_wrqRECyV89KjY0M4usgytHh_ss4LSxI_aw3g=s64","userId":"12354510259357034369"},"user_tz":-330},"id":"hx_8XvhBZpNX","outputId":"ee2b1d04-46f8-4dc6-b42c-8b2e7a4939bd"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 1406 entries, 0 to 1405\n","Data columns (total 7 columns):\n"," #   Column            Non-Null Count  Dtype \n","---  ------            --------------  ----- \n"," 0   word              1406 non-null   object\n"," 1   common_score      1406 non-null   int64 \n"," 2   true_score        1406 non-null   int64 \n"," 3   fake_score        1406 non-null   int64 \n"," 4   doc_common_score  1406 non-null   int64 \n"," 5   doc_true_score    1406 non-null   int64 \n"," 6   doc_fake_score    1406 non-null   int64 \n","dtypes: int64(6), object(1)\n","memory usage: 77.0+ KB\n"]}],"source":["words_df = pd.read_csv(r'/content/drive/Shareddrives/[FYP] Fake News Detection/Kogul_Language_Modelling/ghanashyamvtatti roberta-fake-news/dictionaries/lexicon_WELFake.csv')\n","words_df.info()\n","\n","all_words = words_df['word'].tolist()\n","all_words_embeddings = generate_embeddings(all_words, model, tokenizer)\n","words_df['embedding'] = all_words_embeddings"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":754,"status":"ok","timestamp":1640440722822,"user":{"displayName":"Srikandabala Kogul","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjJ7_wrqRECyV89KjY0M4usgytHh_ss4LSxI_aw3g=s64","userId":"12354510259357034369"},"user_tz":-330},"id":"VNeriqq7nm8B","outputId":"6b6a523a-fbef-4501-8cf8-bcabded9cf5a"},"outputs":[{"data":{"text/plain":["True"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["embeddings = words_df['embedding'].tolist()\n","f = 768\n","\n","ann = AnnoyIndex(f, 'angular')  # Length of item vector that will be indexed\n","for i in range(len(embeddings)):\n","  ann.add_item(i, embeddings[i])\n","\n","ann.build(1000, n_jobs=-1) # 1000 trees"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C84YaefOJgHl"},"outputs":[],"source":["words_df['cumm_true_score'] = multiply(words_df['true_score'], words_df['doc_true_score'])\n","words_df['cumm_fake_score'] = multiply(words_df['fake_score'], words_df['doc_fake_score'])\n","words_df['cumm_common_score'] = multiply(words_df['common_score'], words_df['doc_common_score'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yTxs9_SUJgHm"},"outputs":[],"source":["word_dict = {}\n","\n","for i in range (len(words_df)):\n","  word_dict[words_df['word'][i]] = {}\n","\n","for i in range (len(words_df)):\n","  \n","  word_dict[words_df['word'][i]]['fake_score'] = words_df['fake_score'][i]\n","  word_dict[words_df['word'][i]]['true_score'] = words_df['true_score'][i]\n","  word_dict[words_df['word'][i]]['common_score'] = words_df['common_score'][i]\n","\n","  word_dict[words_df['word'][i]]['doc_fake_score'] = words_df['doc_fake_score'][i]\n","  word_dict[words_df['word'][i]]['doc_true_score'] = words_df['doc_true_score'][i]\n","  word_dict[words_df['word'][i]]['doc_common_score'] = words_df['doc_common_score'][i]\n","\n","  word_dict[words_df['word'][i]]['cumm_fake_score'] = words_df['cumm_fake_score'][i]\n","  word_dict[words_df['word'][i]]['cumm_true_score'] = words_df['cumm_true_score'][i]\n","  word_dict[words_df['word'][i]]['cumm_common_score'] = words_df['cumm_common_score'][i]"]},{"cell_type":"markdown","metadata":{"id":"Q9gJ4AnhXej_"},"source":["## Analysis using LIAR"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3117,"status":"ok","timestamp":1640440726468,"user":{"displayName":"Srikandabala Kogul","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjJ7_wrqRECyV89KjY0M4usgytHh_ss4LSxI_aw3g=s64","userId":"12354510259357034369"},"user_tz":-330},"id":"_H57L4toJgHl","outputId":"30b4c105-5f4b-4613-90fe-2febf75591d2"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 12791 entries, 0 to 12790\n","Data columns (total 15 columns):\n"," #   Column                              Non-Null Count  Dtype  \n","---  ------                              --------------  -----  \n"," 0   ID                                  12791 non-null  object \n"," 1   label                               12791 non-null  object \n"," 2   statement                           12791 non-null  object \n"," 3   subject(s)                          12789 non-null  object \n"," 4   speaker                             12789 non-null  object \n"," 5   speaker_job_title                   9224 non-null   object \n"," 6   state                               10042 non-null  object \n"," 7   party                               12789 non-null  object \n"," 8   credit_history_count_barely_true    12789 non-null  float64\n"," 9   credit_history_count_false          12789 non-null  float64\n"," 10  credit_history_count_half_true      12789 non-null  float64\n"," 11  credit_history_count_mostly_true    12789 non-null  float64\n"," 12  credit_history_count_pants_on_fire  12789 non-null  float64\n"," 13  context                             12660 non-null  object \n"," 14  split                               12791 non-null  object \n","dtypes: float64(5), object(10)\n","memory usage: 1.5+ MB\n"]}],"source":["df = pd.read_csv(r\"/content/drive/Shareddrives/[FYP] Fake News Detection/Datasets/LIAR/Liar_all.csv\")\n","df.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lOZJfTIuJgHm"},"outputs":[],"source":["try:\n","  df = df.loc[df['split'] == 'test']\n","except KeyError:\n","  pass"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":48,"status":"ok","timestamp":1640440726469,"user":{"displayName":"Srikandabala Kogul","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjJ7_wrqRECyV89KjY0M4usgytHh_ss4LSxI_aw3g=s64","userId":"12354510259357034369"},"user_tz":-330},"id":"cvMmEbFuJgHn","outputId":"dbb971b6-920e-4864-f7fe-a1d6f444c30d"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \"\"\"Entry point for launching an IPython kernel.\n"]}],"source":["df['label'] = df['label'].apply(convert_label)\n","\n","df = df.drop_duplicates(subset=[\"statement\"]).reset_index(drop=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CUxvpI9GbFpX"},"outputs":[],"source":["all_words = df['statement'].tolist()\n","all_words_embeddings = []\n","\n","for i in range(0, len(all_words), EMBEDDING_RANGE):\n","  all_words_embeddings.extend(generate_embeddings(all_words[i:i+EMBEDDING_RANGE], model, tokenizer))\n","\n","df['embedding'] = all_words_embeddings"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":139738,"status":"ok","timestamp":1640440879722,"user":{"displayName":"Srikandabala Kogul","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjJ7_wrqRECyV89KjY0M4usgytHh_ss4LSxI_aw3g=s64","userId":"12354510259357034369"},"user_tz":-330},"id":"0ZqZeyLGJgHn","outputId":"35467f69-9cc8-49b0-f40a-a6b55bdec003"},"outputs":[{"name":"stdout","output_type":"stream","text":["The Classification Report for 10 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.5638    0.9958    0.7200       714\n","           1     0.5000    0.0054    0.0107       553\n","\n","    accuracy                         0.5635      1267\n","   macro avg     0.5319    0.5006    0.3654      1267\n","weighted avg     0.5360    0.5635    0.4104      1267\n","\n","===============================================================\n","The Classification Report for 20 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.5630    0.9944    0.7190       714\n","           1     0.3333    0.0036    0.0072       553\n","\n","    accuracy                         0.5620      1267\n","   macro avg     0.4482    0.4990    0.3631      1267\n","weighted avg     0.4628    0.5620    0.4083      1267\n","\n","===============================================================\n","The Classification Report for 30 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.5634    0.9958    0.7196       714\n","           1     0.4000    0.0036    0.0072       553\n","\n","    accuracy                         0.5627      1267\n","   macro avg     0.4817    0.4997    0.3634      1267\n","weighted avg     0.4921    0.5627    0.4087      1267\n","\n","===============================================================\n","The Classification Report for 40 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.5637    0.9972    0.7203       714\n","           1     0.5000    0.0036    0.0072       553\n","\n","    accuracy                         0.5635      1267\n","   macro avg     0.5319    0.5004    0.3637      1267\n","weighted avg     0.5359    0.5635    0.4090      1267\n","\n","===============================================================\n","The Classification Report for 50 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.5637    0.9972    0.7203       714\n","           1     0.5000    0.0036    0.0072       553\n","\n","    accuracy                         0.5635      1267\n","   macro avg     0.5319    0.5004    0.3637      1267\n","weighted avg     0.5359    0.5635    0.4090      1267\n","\n","===============================================================\n","The Classification Report for 60 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.5637    0.9972    0.7203       714\n","           1     0.5000    0.0036    0.0072       553\n","\n","    accuracy                         0.5635      1267\n","   macro avg     0.5319    0.5004    0.3637      1267\n","weighted avg     0.5359    0.5635    0.4090      1267\n","\n","===============================================================\n","The Classification Report for 70 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.5637    0.9972    0.7203       714\n","           1     0.5000    0.0036    0.0072       553\n","\n","    accuracy                         0.5635      1267\n","   macro avg     0.5319    0.5004    0.3637      1267\n","weighted avg     0.5359    0.5635    0.4090      1267\n","\n","===============================================================\n","The Classification Report for 80 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.5637    0.9972    0.7203       714\n","           1     0.5000    0.0036    0.0072       553\n","\n","    accuracy                         0.5635      1267\n","   macro avg     0.5319    0.5004    0.3637      1267\n","weighted avg     0.5359    0.5635    0.4090      1267\n","\n","===============================================================\n","The Classification Report for 90 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.5637    0.9972    0.7203       714\n","           1     0.5000    0.0036    0.0072       553\n","\n","    accuracy                         0.5635      1267\n","   macro avg     0.5319    0.5004    0.3637      1267\n","weighted avg     0.5359    0.5635    0.4090      1267\n","\n","===============================================================\n","The Classification Report for 100 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.5637    0.9972    0.7203       714\n","           1     0.5000    0.0036    0.0072       553\n","\n","    accuracy                         0.5635      1267\n","   macro avg     0.5319    0.5004    0.3637      1267\n","weighted avg     0.5359    0.5635    0.4090      1267\n","\n","===============================================================\n","The Classification Report for 110 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.5637    0.9972    0.7203       714\n","           1     0.5000    0.0036    0.0072       553\n","\n","    accuracy                         0.5635      1267\n","   macro avg     0.5319    0.5004    0.3637      1267\n","weighted avg     0.5359    0.5635    0.4090      1267\n","\n","===============================================================\n","The Classification Report for 120 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.5637    0.9972    0.7203       714\n","           1     0.5000    0.0036    0.0072       553\n","\n","    accuracy                         0.5635      1267\n","   macro avg     0.5319    0.5004    0.3637      1267\n","weighted avg     0.5359    0.5635    0.4090      1267\n","\n","===============================================================\n","The Classification Report for 130 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.5633    0.9972    0.7199       714\n","           1     0.3333    0.0018    0.0036       553\n","\n","    accuracy                         0.5627      1267\n","   macro avg     0.4483    0.4995    0.3618      1267\n","weighted avg     0.4629    0.5627    0.4073      1267\n","\n","===============================================================\n","The Classification Report for 140 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.5636    0.9986    0.7206       714\n","           1     0.5000    0.0018    0.0036       553\n","\n","    accuracy                         0.5635      1267\n","   macro avg     0.5318    0.5002    0.3621      1267\n","weighted avg     0.5359    0.5635    0.4076      1267\n","\n","===============================================================\n","The Classification Report for 150 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.5636    0.9986    0.7206       714\n","           1     0.5000    0.0018    0.0036       553\n","\n","    accuracy                         0.5635      1267\n","   macro avg     0.5318    0.5002    0.3621      1267\n","weighted avg     0.5359    0.5635    0.4076      1267\n","\n","===============================================================\n","The Classification Report for 160 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.5636    0.9986    0.7206       714\n","           1     0.5000    0.0018    0.0036       553\n","\n","    accuracy                         0.5635      1267\n","   macro avg     0.5318    0.5002    0.3621      1267\n","weighted avg     0.5359    0.5635    0.4076      1267\n","\n","===============================================================\n","The Classification Report for 170 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.5636    0.9986    0.7206       714\n","           1     0.5000    0.0018    0.0036       553\n","\n","    accuracy                         0.5635      1267\n","   macro avg     0.5318    0.5002    0.3621      1267\n","weighted avg     0.5359    0.5635    0.4076      1267\n","\n","===============================================================\n","The Classification Report for 180 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.5636    0.9986    0.7206       714\n","           1     0.5000    0.0018    0.0036       553\n","\n","    accuracy                         0.5635      1267\n","   macro avg     0.5318    0.5002    0.3621      1267\n","weighted avg     0.5359    0.5635    0.4076      1267\n","\n","===============================================================\n","The Classification Report for 190 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.5640    1.0000    0.7212       714\n","           1     1.0000    0.0018    0.0036       553\n","\n","    accuracy                         0.5643      1267\n","   macro avg     0.7820    0.5009    0.3624      1267\n","weighted avg     0.7543    0.5643    0.4080      1267\n","\n","===============================================================\n"]}],"source":["y_true = df['label'].tolist()\n","\n","for k in range(10, 200, 10):\n","\n","  y_pred = []\n","\n","  # for i in trange(len(df)):\n","  for i in range(len(df)):\n","\n","    true, fake = 0, 0\n","\n","    indexes, distances = ann.get_nns_by_vector(df['embedding'][i], k, include_distances=True, search_k=-1)\n","\n","    for j in range(len(indexes)):\n","      # true += words_df['true_score'][indexes[j]]\n","      # fake += words_df['fake_score'][indexes[j]]\n","\n","      # true += words_df['doc_true_score'][indexes[j]]\n","      # fake += words_df['doc_fake_score'][indexes[j]]\n","\n","      true += words_df['doc_true_score'][indexes[j]]\n","      fake += words_df['doc_fake_score'][indexes[j]]\n","      \n","    if true > fake:\n","      y_pred.append(0)\n","    else:\n","      y_pred.append(1)\n","    # print(true, fake, df['label'][i])\n","\n","  print(f\"The Classification Report for {k} words\")\n","  print()\n","  print(classification_report(y_true, y_pred, digits = 4))\n","  print(\"===============================================================\")"]},{"cell_type":"markdown","metadata":{"id":"2Ov84CcLrg4H"},"source":["## Analysis using FakeNewsNet"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2818,"status":"ok","timestamp":1640440882493,"user":{"displayName":"Srikandabala Kogul","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjJ7_wrqRECyV89KjY0M4usgytHh_ss4LSxI_aw3g=s64","userId":"12354510259357034369"},"user_tz":-330},"id":"tBOH7w50rg4I","outputId":"7942a75f-fc1a-468a-e7eb-6af6ec712bc9"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 23196 entries, 0 to 23195\n","Data columns (total 7 columns):\n"," #   Column     Non-Null Count  Dtype \n","---  ------     --------------  ----- \n"," 0   id         23196 non-null  object\n"," 1   news_url   22866 non-null  object\n"," 2   title      23196 non-null  object\n"," 3   tweet_ids  21695 non-null  object\n"," 4   label      23196 non-null  object\n"," 5   source     22140 non-null  object\n"," 6   id_1       23196 non-null  int64 \n","dtypes: int64(1), object(6)\n","memory usage: 1.2+ MB\n"]}],"source":["df = pd.read_csv(r\"/content/drive/Shareddrives/[FYP] Fake News Detection/Datasets/FakeNewsNet/FakeNewsNet_All.csv\")\n","df.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p5xvHMzArg4K"},"outputs":[],"source":["try:\n","  df = df.loc[df['split'] == 'test']\n","except KeyError:\n","  pass"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"esQ1XLStrg4L"},"outputs":[],"source":["df['label'] = df['label'].apply(convert_label)\n","\n","df = df.drop_duplicates(subset=[\"title\"]).reset_index(drop=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pZThKKwarg4L"},"outputs":[],"source":["all_words = df['title'].tolist()\n","all_words_embeddings = []\n","\n","for i in range(0, len(all_words), EMBEDDING_RANGE):\n","  all_words_embeddings.extend(generate_embeddings(all_words[i:i+EMBEDDING_RANGE], model, tokenizer))\n","\n","df['embedding'] = all_words_embeddings"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2523614,"status":"ok","timestamp":1640443456346,"user":{"displayName":"Srikandabala Kogul","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjJ7_wrqRECyV89KjY0M4usgytHh_ss4LSxI_aw3g=s64","userId":"12354510259357034369"},"user_tz":-330},"id":"Z2KQjKvwrg4M","outputId":"8799a95e-0e34-4e87-fd4c-51453407054d"},"outputs":[{"name":"stdout","output_type":"stream","text":["The Classification Report for 10 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.7508    0.6925    0.7205     16402\n","           1     0.2353    0.2916    0.2604      5322\n","\n","    accuracy                         0.5943     21724\n","   macro avg     0.4930    0.4920    0.4905     21724\n","weighted avg     0.6245    0.5943    0.6078     21724\n","\n","===============================================================\n","The Classification Report for 20 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.7511    0.7318    0.7413     16402\n","           1     0.2340    0.2525    0.2429      5322\n","\n","    accuracy                         0.6144     21724\n","   macro avg     0.4926    0.4922    0.4921     21724\n","weighted avg     0.6244    0.6144    0.6192     21724\n","\n","===============================================================\n","The Classification Report for 30 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.7529    0.7495    0.7512     16402\n","           1     0.2387    0.2420    0.2403      5322\n","\n","    accuracy                         0.6252     21724\n","   macro avg     0.4958    0.4957    0.4958     21724\n","weighted avg     0.6269    0.6252    0.6260     21724\n","\n","===============================================================\n","The Classification Report for 40 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.7527    0.7589    0.7558     16402\n","           1     0.2377    0.2317    0.2347      5322\n","\n","    accuracy                         0.6298     21724\n","   macro avg     0.4952    0.4953    0.4952     21724\n","weighted avg     0.6266    0.6298    0.6281     21724\n","\n","===============================================================\n","The Classification Report for 50 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.7534    0.7701    0.7617     16402\n","           1     0.2396    0.2232    0.2311      5322\n","\n","    accuracy                         0.6361     21724\n","   macro avg     0.4965    0.4967    0.4964     21724\n","weighted avg     0.6275    0.6361    0.6317     21724\n","\n","===============================================================\n","The Classification Report for 60 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.7539    0.7778    0.7656     16402\n","           1     0.2409    0.2174    0.2286      5322\n","\n","    accuracy                         0.6405     21724\n","   macro avg     0.4974    0.4976    0.4971     21724\n","weighted avg     0.6282    0.6405    0.6341     21724\n","\n","===============================================================\n","The Classification Report for 70 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.7537    0.7844    0.7688     16402\n","           1     0.2402    0.2101    0.2241      5322\n","\n","    accuracy                         0.6437     21724\n","   macro avg     0.4970    0.4972    0.4964     21724\n","weighted avg     0.6279    0.6437    0.6353     21724\n","\n","===============================================================\n","The Classification Report for 80 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.7541    0.7930    0.7730     16402\n","           1     0.2413    0.2029    0.2205      5322\n","\n","    accuracy                         0.6484     21724\n","   macro avg     0.4977    0.4979    0.4967     21724\n","weighted avg     0.6284    0.6484    0.6376     21724\n","\n","===============================================================\n","The Classification Report for 90 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.7539    0.8000    0.7763     16402\n","           1     0.2406    0.1952    0.2155      5322\n","\n","    accuracy                         0.6519     21724\n","   macro avg     0.4972    0.4976    0.4959     21724\n","weighted avg     0.6282    0.6519    0.6389     21724\n","\n","===============================================================\n","The Classification Report for 100 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.7545    0.8079    0.7803     16402\n","           1     0.2429    0.1900    0.2132      5322\n","\n","    accuracy                         0.6565     21724\n","   macro avg     0.4987    0.4989    0.4967     21724\n","weighted avg     0.6292    0.6565    0.6414     21724\n","\n","===============================================================\n","The Classification Report for 110 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.7544    0.8136    0.7829     16402\n","           1     0.2423    0.1838    0.2090      5322\n","\n","    accuracy                         0.6593     21724\n","   macro avg     0.4984    0.4987    0.4959     21724\n","weighted avg     0.6290    0.6593    0.6423     21724\n","\n","===============================================================\n","The Classification Report for 120 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.7545    0.8197    0.7857     16402\n","           1     0.2425    0.1779    0.2053      5322\n","\n","    accuracy                         0.6624     21724\n","   macro avg     0.4985    0.4988    0.4955     21724\n","weighted avg     0.6291    0.6624    0.6435     21724\n","\n","===============================================================\n","The Classification Report for 130 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.7540    0.8254    0.7881     16402\n","           1     0.2402    0.1700    0.1991      5322\n","\n","    accuracy                         0.6649     21724\n","   macro avg     0.4971    0.4977    0.4936     21724\n","weighted avg     0.6281    0.6649    0.6438     21724\n","\n","===============================================================\n","The Classification Report for 140 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.7538    0.8314    0.7907     16402\n","           1     0.2391    0.1633    0.1940      5322\n","\n","    accuracy                         0.6677     21724\n","   macro avg     0.4964    0.4973    0.4924     21724\n","weighted avg     0.6277    0.6677    0.6445     21724\n","\n","===============================================================\n","The Classification Report for 150 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.7536    0.8374    0.7933     16402\n","           1     0.2376    0.1561    0.1884      5322\n","\n","    accuracy                         0.6705     21724\n","   macro avg     0.4956    0.4968    0.4909     21724\n","weighted avg     0.6272    0.6705    0.6451     21724\n","\n","===============================================================\n","The Classification Report for 160 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.7542    0.8429    0.7961     16402\n","           1     0.2407    0.1535    0.1875      5322\n","\n","    accuracy                         0.6740     21724\n","   macro avg     0.4975    0.4982    0.4918     21724\n","weighted avg     0.6284    0.6740    0.6470     21724\n","\n","===============================================================\n","The Classification Report for 170 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.7532    0.8485    0.7980     16402\n","           1     0.2344    0.1430    0.1776      5322\n","\n","    accuracy                         0.6757     21724\n","   macro avg     0.4938    0.4957    0.4878     21724\n","weighted avg     0.6261    0.6757    0.6460     21724\n","\n","===============================================================\n","The Classification Report for 180 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.7534    0.8570    0.8019     16402\n","           1     0.2352    0.1355    0.1719      5322\n","\n","    accuracy                         0.6803     21724\n","   macro avg     0.4943    0.4963    0.4869     21724\n","weighted avg     0.6264    0.6803    0.6476     21724\n","\n","===============================================================\n","The Classification Report for 190 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.7537    0.8661    0.8060     16402\n","           1     0.2364    0.1278    0.1659      5322\n","\n","    accuracy                         0.6852     21724\n","   macro avg     0.4951    0.4969    0.4860     21724\n","weighted avg     0.6270    0.6852    0.6492     21724\n","\n","===============================================================\n"]}],"source":["y_true = df['label'].tolist()\n","\n","for k in range(10, 200, 10):\n","\n","  y_pred = []\n","\n","  # for i in trange(len(df)):\n","  for i in range(len(df)):\n","\n","    true, fake = 0, 0\n","\n","    indexes, distances = ann.get_nns_by_vector(df['embedding'][i], k, include_distances=True, search_k=-1)\n","\n","    for j in range(len(indexes)):\n","      # true += words_df['true_score'][indexes[j]]\n","      # fake += words_df['fake_score'][indexes[j]]\n","\n","      # true += words_df['doc_true_score'][indexes[j]]\n","      # fake += words_df['doc_fake_score'][indexes[j]]\n","\n","      true += words_df['doc_true_score'][indexes[j]]\n","      fake += words_df['doc_fake_score'][indexes[j]]\n","\n","    if true > fake:\n","      y_pred.append(0)\n","    else:\n","      y_pred.append(1)\n","    # print(true, fake, df['label'][i])\n","\n","  print(f\"The Classification Report for {k} words\")\n","  print()\n","  print(classification_report(y_true, y_pred, digits = 4))\n","  print(\"===============================================================\")"]},{"cell_type":"markdown","metadata":{"id":"grRq4YQMtdid"},"source":["## Analysis using CodaLab"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2263,"status":"ok","timestamp":1640443458583,"user":{"displayName":"Srikandabala Kogul","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjJ7_wrqRECyV89KjY0M4usgytHh_ss4LSxI_aw3g=s64","userId":"12354510259357034369"},"user_tz":-330},"id":"L4tRRkJytdif","outputId":"875972d4-e2af-400e-e3c4-9b2052c793d7"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 10700 entries, 0 to 10699\n","Data columns (total 4 columns):\n"," #   Column  Non-Null Count  Dtype \n","---  ------  --------------  ----- \n"," 0   id      10700 non-null  object\n"," 1   tweet   10700 non-null  object\n"," 2   label   10700 non-null  object\n"," 3   split   10700 non-null  object\n","dtypes: object(4)\n","memory usage: 334.5+ KB\n"]}],"source":["df = pd.read_csv(r\"/content/drive/Shareddrives/[FYP] Fake News Detection/Datasets/CodaLab Covid/Constraint_English_All.csv\")\n","df.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rIiOXZM6tdig"},"outputs":[],"source":["try:\n","  df = df.loc[df['split'] == 'test']\n","except KeyError:\n","  pass"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40,"status":"ok","timestamp":1640443458585,"user":{"displayName":"Srikandabala Kogul","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjJ7_wrqRECyV89KjY0M4usgytHh_ss4LSxI_aw3g=s64","userId":"12354510259357034369"},"user_tz":-330},"id":"iP1-_mzJtdih","outputId":"dc4af033-5e5c-4f8a-a2fa-ec8b90f2bb7e"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \"\"\"Entry point for launching an IPython kernel.\n"]}],"source":["df['label'] = df['label'].apply(convert_label)\n","\n","df = df.drop_duplicates(subset=[\"tweet\"]).reset_index(drop=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PumHRFcDtdig"},"outputs":[],"source":["all_words = df['tweet'].tolist()\n","all_words_embeddings = []\n","\n","for i in range(0, len(all_words), EMBEDDING_RANGE):\n","  all_words_embeddings.extend(generate_embeddings(all_words[i:i+EMBEDDING_RANGE], model, tokenizer))\n","\n","df['embedding'] = all_words_embeddings"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":257429,"status":"ok","timestamp":1640443741982,"user":{"displayName":"Srikandabala Kogul","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjJ7_wrqRECyV89KjY0M4usgytHh_ss4LSxI_aw3g=s64","userId":"12354510259357034369"},"user_tz":-330},"id":"VRxJZum0tdii","outputId":"cdfefc3c-28e6-40e0-a19b-ed1ab82b963e"},"outputs":[{"name":"stdout","output_type":"stream","text":["The Classification Report for 10 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.3126    0.2286    0.2641      1120\n","           1     0.3460    0.4480    0.3904      1020\n","\n","    accuracy                         0.3332      2140\n","   macro avg     0.3293    0.3383    0.3272      2140\n","weighted avg     0.3285    0.3332    0.3243      2140\n","\n","===============================================================\n","The Classification Report for 20 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.3302    0.2536    0.2869      1120\n","           1     0.3469    0.4353    0.3861      1020\n","\n","    accuracy                         0.3402      2140\n","   macro avg     0.3386    0.3444    0.3365      2140\n","weighted avg     0.3382    0.3402    0.3342      2140\n","\n","===============================================================\n","The Classification Report for 30 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.3326    0.2616    0.2929      1120\n","           1     0.3431    0.4235    0.3791      1020\n","\n","    accuracy                         0.3388      2140\n","   macro avg     0.3379    0.3426    0.3360      2140\n","weighted avg     0.3376    0.3388    0.3340      2140\n","\n","===============================================================\n","The Classification Report for 40 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.3446    0.2830    0.3108      1120\n","           1     0.3418    0.4088    0.3723      1020\n","\n","    accuracy                         0.3430      2140\n","   macro avg     0.3432    0.3459    0.3416      2140\n","weighted avg     0.3432    0.3430    0.3401      2140\n","\n","===============================================================\n","The Classification Report for 50 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.3505    0.2911    0.3180      1120\n","           1     0.3438    0.4078    0.3731      1020\n","\n","    accuracy                         0.3467      2140\n","   macro avg     0.3472    0.3495    0.3456      2140\n","weighted avg     0.3473    0.3467    0.3443      2140\n","\n","===============================================================\n","The Classification Report for 60 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.3518    0.2955    0.3212      1120\n","           1     0.3420    0.4020    0.3695      1020\n","\n","    accuracy                         0.3463      2140\n","   macro avg     0.3469    0.3487    0.3454      2140\n","weighted avg     0.3471    0.3463    0.3442      2140\n","\n","===============================================================\n","The Classification Report for 70 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.3562    0.3063    0.3293      1120\n","           1     0.3398    0.3922    0.3641      1020\n","\n","    accuracy                         0.3472      2140\n","   macro avg     0.3480    0.3492    0.3467      2140\n","weighted avg     0.3484    0.3472    0.3459      2140\n","\n","===============================================================\n","The Classification Report for 80 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.3609    0.3152    0.3365      1120\n","           1     0.3399    0.3873    0.3621      1020\n","\n","    accuracy                         0.3495      2140\n","   macro avg     0.3504    0.3512    0.3493      2140\n","weighted avg     0.3509    0.3495    0.3487      2140\n","\n","===============================================================\n","The Classification Report for 90 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.3683    0.3259    0.3458      1120\n","           1     0.3429    0.3863    0.3633      1020\n","\n","    accuracy                         0.3547      2140\n","   macro avg     0.3556    0.3561    0.3546      2140\n","weighted avg     0.3562    0.3547    0.3541      2140\n","\n","===============================================================\n","The Classification Report for 100 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.3719    0.3357    0.3529      1120\n","           1     0.3410    0.3775    0.3583      1020\n","\n","    accuracy                         0.3556      2140\n","   macro avg     0.3565    0.3566    0.3556      2140\n","weighted avg     0.3572    0.3556    0.3555      2140\n","\n","===============================================================\n","The Classification Report for 110 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.3782    0.3464    0.3616      1120\n","           1     0.3429    0.3745    0.3580      1020\n","\n","    accuracy                         0.3598      2140\n","   macro avg     0.3605    0.3605    0.3598      2140\n","weighted avg     0.3614    0.3598    0.3599      2140\n","\n","===============================================================\n","The Classification Report for 120 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.3835    0.3571    0.3699      1120\n","           1     0.3437    0.3696    0.3562      1020\n","\n","    accuracy                         0.3631      2140\n","   macro avg     0.3636    0.3634    0.3630      2140\n","weighted avg     0.3645    0.3631    0.3633      2140\n","\n","===============================================================\n","The Classification Report for 130 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.3934    0.3741    0.3835      1120\n","           1     0.3479    0.3667    0.3570      1020\n","\n","    accuracy                         0.3706      2140\n","   macro avg     0.3707    0.3704    0.3703      2140\n","weighted avg     0.3717    0.3706    0.3709      2140\n","\n","===============================================================\n","The Classification Report for 140 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.4011    0.3857    0.3933      1120\n","           1     0.3528    0.3676    0.3601      1020\n","\n","    accuracy                         0.3771      2140\n","   macro avg     0.3769    0.3767    0.3767      2140\n","weighted avg     0.3781    0.3771    0.3774      2140\n","\n","===============================================================\n","The Classification Report for 150 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.3993    0.3839    0.3914      1120\n","           1     0.3509    0.3657    0.3581      1020\n","\n","    accuracy                         0.3752      2140\n","   macro avg     0.3751    0.3748    0.3748      2140\n","weighted avg     0.3762    0.3752    0.3756      2140\n","\n","===============================================================\n","The Classification Report for 160 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.4042    0.3937    0.3989      1120\n","           1     0.3527    0.3627    0.3577      1020\n","\n","    accuracy                         0.3790      2140\n","   macro avg     0.3785    0.3782    0.3783      2140\n","weighted avg     0.3797    0.3790    0.3793      2140\n","\n","===============================================================\n","The Classification Report for 170 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.4086    0.4054    0.4070      1120\n","           1     0.3528    0.3559    0.3543      1020\n","\n","    accuracy                         0.3818      2140\n","   macro avg     0.3807    0.3806    0.3807      2140\n","weighted avg     0.3820    0.3818    0.3819      2140\n","\n","===============================================================\n","The Classification Report for 180 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.4061    0.4071    0.4066      1120\n","           1     0.3471    0.3461    0.3466      1020\n","\n","    accuracy                         0.3780      2140\n","   macro avg     0.3766    0.3766    0.3766      2140\n","weighted avg     0.3780    0.3780    0.3780      2140\n","\n","===============================================================\n","The Classification Report for 190 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.4103    0.4250    0.4175      1120\n","           1     0.3429    0.3294    0.3360      1020\n","\n","    accuracy                         0.3794      2140\n","   macro avg     0.3766    0.3772    0.3768      2140\n","weighted avg     0.3782    0.3794    0.3787      2140\n","\n","===============================================================\n"]}],"source":["y_true = df['label'].tolist()\n","\n","for k in range(10, 200, 10):\n","\n","  y_pred = []\n","\n","  # for i in trange(len(df)):\n","  for i in range(len(df)):\n","\n","    true, fake = 0, 0\n","\n","    indexes, distances = ann.get_nns_by_vector(df['embedding'][i], k, include_distances=True, search_k=-1)\n","\n","    for j in range(len(indexes)):\n","      # true += words_df['true_score'][indexes[j]]\n","      # fake += words_df['fake_score'][indexes[j]]\n","\n","      # true += words_df['doc_true_score'][indexes[j]]\n","      # fake += words_df['doc_fake_score'][indexes[j]]\n","\n","      true += words_df['doc_true_score'][indexes[j]]\n","      fake += words_df['doc_fake_score'][indexes[j]]\n","\n","    if true > fake:\n","      y_pred.append(0)\n","    else:\n","      y_pred.append(1)\n","    # print(true, fake, df['label'][i])\n","\n","  print(f\"The Classification Report for {k} words\")\n","  print()\n","  print(classification_report(y_true, y_pred, digits = 4))\n","  print(\"===============================================================\")"]},{"cell_type":"markdown","metadata":{"id":"gaSq5vrsudgp"},"source":["## Analysis using ISOT"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4154,"status":"ok","timestamp":1640443746079,"user":{"displayName":"Srikandabala Kogul","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjJ7_wrqRECyV89KjY0M4usgytHh_ss4LSxI_aw3g=s64","userId":"12354510259357034369"},"user_tz":-330},"id":"eRvBAy-Qudgq","outputId":"13fc2744-5e9b-4690-ac2e-fab8c0c8667a"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 44898 entries, 0 to 44897\n","Data columns (total 6 columns):\n"," #   Column   Non-Null Count  Dtype \n","---  ------   --------------  ----- \n"," 0   title    44898 non-null  object\n"," 1   text     44898 non-null  object\n"," 2   subject  44898 non-null  object\n"," 3   date     44898 non-null  object\n"," 4   label    44898 non-null  int64 \n"," 5   id       44898 non-null  int64 \n","dtypes: int64(2), object(4)\n","memory usage: 2.1+ MB\n"]}],"source":["df = pd.read_csv(r\"/content/drive/Shareddrives/[FYP] Fake News Detection/Datasets/ISOT/ISOT.csv\")\n","df.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2yrl5OpYudgr"},"outputs":[],"source":["try:\n","  df = df.loc[df['split'] == 'test']\n","except KeyError:\n","  pass"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cT0lU4UMudgs"},"outputs":[],"source":["df['label'] = df['label'].apply(convert_label)\n","\n","df['total_text'] = df['title'].fillna('') + \" \" + df['text'].fillna('')\n","df = df.drop_duplicates(subset=[\"total_text\"]).reset_index(drop=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rXLOZpncudgs"},"outputs":[],"source":["all_words = df['total_text'].tolist()\n","all_words_embeddings = []\n","\n","for i in range(0, len(all_words), EMBEDDING_RANGE):\n","  all_words_embeddings.extend(generate_embeddings(all_words[i:i+EMBEDDING_RANGE], model, tokenizer))\n","\n","df['embedding'] = all_words_embeddings"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FG7zvgHnudgt","outputId":"25e10480-81f4-4039-d519-001266709b81"},"outputs":[{"name":"stdout","output_type":"stream","text":["The Classification Report for 10 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.7724    0.9986    0.8711     21197\n","           1     0.9975    0.6517    0.7883     17908\n","\n","    accuracy                         0.8397     39105\n","   macro avg     0.8850    0.8251    0.8297     39105\n","weighted avg     0.8755    0.8397    0.8332     39105\n","\n","===============================================================\n","The Classification Report for 20 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.7453    0.9992    0.8537     21197\n","           1     0.9983    0.5958    0.7462     17908\n","\n","    accuracy                         0.8144     39105\n","   macro avg     0.8718    0.7975    0.8000     39105\n","weighted avg     0.8611    0.8144    0.8045     39105\n","\n","===============================================================\n","The Classification Report for 30 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.7199    0.9995    0.8369     21197\n","           1     0.9989    0.5396    0.7007     17908\n","\n","    accuracy                         0.7889     39105\n","   macro avg     0.8594    0.7695    0.7688     39105\n","weighted avg     0.8476    0.7889    0.7745     39105\n","\n","===============================================================\n","The Classification Report for 40 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.7029    0.9996    0.8254     21197\n","           1     0.9991    0.4999    0.6664     17908\n","\n","    accuracy                         0.7708     39105\n","   macro avg     0.8510    0.7498    0.7459     39105\n","weighted avg     0.8386    0.7708    0.7526     39105\n","\n","===============================================================\n","The Classification Report for 50 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.6883    0.9997    0.8153     21197\n","           1     0.9992    0.4641    0.6338     17908\n","\n","    accuracy                         0.7544     39105\n","   macro avg     0.8437    0.7319    0.7245     39105\n","weighted avg     0.8306    0.7544    0.7322     39105\n","\n","===============================================================\n","The Classification Report for 60 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.6798    0.9998    0.8093     21197\n","           1     0.9995    0.4426    0.6135     17908\n","\n","    accuracy                         0.7446     39105\n","   macro avg     0.8397    0.7212    0.7114     39105\n","weighted avg     0.8262    0.7446    0.7197     39105\n","\n","===============================================================\n","The Classification Report for 70 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.6745    0.9998    0.8055     21197\n","           1     0.9993    0.4289    0.6002     17908\n","\n","    accuracy                         0.7383     39105\n","   macro avg     0.8369    0.7143    0.7028     39105\n","weighted avg     0.8233    0.7383    0.7115     39105\n","\n","===============================================================\n","The Classification Report for 80 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.6707    0.9998    0.8028     21197\n","           1     0.9993    0.4190    0.5904     17908\n","\n","    accuracy                         0.7338     39105\n","   macro avg     0.8350    0.7094    0.6966     39105\n","weighted avg     0.8212    0.7338    0.7055     39105\n","\n","===============================================================\n","The Classification Report for 90 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.6682    0.9998    0.8010     21197\n","           1     0.9993    0.4123    0.5837     17908\n","\n","    accuracy                         0.7307     39105\n","   macro avg     0.8337    0.7060    0.6924     39105\n","weighted avg     0.8198    0.7307    0.7015     39105\n","\n","===============================================================\n","The Classification Report for 100 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.6659    0.9998    0.7994     21197\n","           1     0.9993    0.4064    0.5778     17908\n","\n","    accuracy                         0.7280     39105\n","   macro avg     0.8326    0.7031    0.6886     39105\n","weighted avg     0.8186    0.7280    0.6979     39105\n","\n","===============================================================\n","The Classification Report for 110 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.6642    0.9997    0.7982     21197\n","           1     0.9992    0.4018    0.5732     17908\n","\n","    accuracy                         0.7259     39105\n","   macro avg     0.8317    0.7008    0.6857     39105\n","weighted avg     0.8176    0.7259    0.6951     39105\n","\n","===============================================================\n","The Classification Report for 120 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.6616    0.9997    0.7963     21197\n","           1     0.9992    0.3949    0.5660     17908\n","\n","    accuracy                         0.7227     39105\n","   macro avg     0.8304    0.6973    0.6811     39105\n","weighted avg     0.8162    0.7227    0.6908     39105\n","\n","===============================================================\n","The Classification Report for 130 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.6566    0.9998    0.7926     21197\n","           1     0.9993    0.3810    0.5517     17908\n","\n","    accuracy                         0.7164     39105\n","   macro avg     0.8279    0.6904    0.6721     39105\n","weighted avg     0.8135    0.7164    0.6823     39105\n","\n","===============================================================\n","The Classification Report for 140 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.6513    0.9998    0.7888     21197\n","           1     0.9992    0.3665    0.5363     17908\n","\n","    accuracy                         0.7098     39105\n","   macro avg     0.8253    0.6831    0.6625     39105\n","weighted avg     0.8106    0.7098    0.6731     39105\n","\n","===============================================================\n","The Classification Report for 150 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.6469    0.9999    0.7856     21197\n","           1     0.9995    0.3540    0.5229     17908\n","\n","    accuracy                         0.7041     39105\n","   macro avg     0.8232    0.6769    0.6542     39105\n","weighted avg     0.8084    0.7041    0.6653     39105\n","\n","===============================================================\n","The Classification Report for 160 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.6437    0.9999    0.7832     21197\n","           1     0.9997    0.3449    0.5128     17908\n","\n","    accuracy                         0.6999     39105\n","   macro avg     0.8217    0.6724    0.6480     39105\n","weighted avg     0.8067    0.6999    0.6594     39105\n","\n","===============================================================\n","The Classification Report for 170 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.6399    0.9999    0.7804     21197\n","           1     0.9995    0.3340    0.5007     17908\n","\n","    accuracy                         0.6949     39105\n","   macro avg     0.8197    0.6669    0.6406     39105\n","weighted avg     0.8046    0.6949    0.6523     39105\n","\n","===============================================================\n","The Classification Report for 180 words\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.6360    0.9999    0.7774     21197\n","           1     0.9997    0.3225    0.4877     17908\n","\n","    accuracy                         0.6897     39105\n","   macro avg     0.8178    0.6612    0.6325     39105\n","weighted avg     0.8025    0.6897    0.6447     39105\n","\n","===============================================================\n"]}],"source":["y_true = df['label'].tolist()\n","\n","for k in range(10, 200, 10):\n","\n","  y_pred = []\n","\n","  # for i in trange(len(df)):\n","  for i in range(len(df)):\n","\n","    true, fake = 0, 0\n","\n","    indexes, distances = ann.get_nns_by_vector(df['embedding'][i], k, include_distances=True, search_k=-1)\n","\n","    for j in range(len(indexes)):\n","      # true += words_df['true_score'][indexes[j]]\n","      # fake += words_df['fake_score'][indexes[j]]\n","\n","      # true += words_df['doc_true_score'][indexes[j]]\n","      # fake += words_df['doc_fake_score'][indexes[j]]\n","\n","      true += words_df['doc_true_score'][indexes[j]]\n","      fake += words_df['doc_fake_score'][indexes[j]]\n","\n","    if true > fake:\n","      y_pred.append(0)\n","    else:\n","      y_pred.append(1)\n","    # print(true, fake, df['label'][i])\n","\n","  print(f\"The Classification Report for {k} words\")\n","  print()\n","  print(classification_report(y_true, y_pred, digits = 4))\n","  print(\"===============================================================\")"]},{"cell_type":"markdown","metadata":{"id":"mgZ-JLB7wudk"},"source":["## Analysis using Kaggle"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HYw8PEThwudl"},"outputs":[],"source":["df = pd.read_csv(r\"/content/drive/Shareddrives/[FYP] Fake News Detection/Datasets/Kaggle_real_fake/fake_or_real_news.csv\")\n","df.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gHoGZoCTwudm"},"outputs":[],"source":["try:\n","  df = df.loc[df['split'] == 'test']\n","except KeyError:\n","  pass"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"95jI1Kiewuds"},"outputs":[],"source":["df['label'] = df['label'].apply(convert_label)\n","\n","df['total_text'] = df['title'].fillna('') + \" \" + df['text'].fillna('')\n","df = df.drop_duplicates(subset=[\"total_text\"]).reset_index(drop=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bhJnDTqhwudq"},"outputs":[],"source":["all_words = df['total_text'].tolist()\n","all_words_embeddings = []\n","\n","for i in range(0, len(all_words), EMBEDDING_RANGE):\n","  all_words_embeddings.extend(generate_embeddings(all_words[i:i+EMBEDDING_RANGE], model, tokenizer))\n","\n","df['embedding'] = all_words_embeddings"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nhzv5Umtwudt"},"outputs":[],"source":["y_true = df['label'].tolist()\n","\n","for k in range(10, 200, 10):\n","\n","  y_pred = []\n","\n","  # for i in trange(len(df)):\n","  for i in range(len(df)):\n","\n","    true, fake = 0, 0\n","\n","    indexes, distances = ann.get_nns_by_vector(df['embedding'][i], k, include_distances=True, search_k=-1)\n","\n","    for j in range(len(indexes)):\n","      # true += words_df['true_score'][indexes[j]]\n","      # fake += words_df['fake_score'][indexes[j]]\n","\n","      # true += words_df['doc_true_score'][indexes[j]]\n","      # fake += words_df['doc_fake_score'][indexes[j]]\n","\n","      true += words_df['doc_true_score'][indexes[j]]\n","      fake += words_df['doc_fake_score'][indexes[j]]\n","\n","    if true > fake:\n","      y_pred.append(0)\n","    else:\n","      y_pred.append(1)\n","    # print(true, fake, df['label'][i])\n","\n","  print(f\"The Classification Report for {k} words\")\n","  print()\n","  print(classification_report(y_true, y_pred, digits = 4))\n","  print(\"===============================================================\")"]}],"metadata":{"accelerator":"GPU","colab":{"name":"[25/12/2021] Sentence Transformers.ipynb","provenance":[],"mount_file_id":"1jYHDPSwDa0Ak0mFGhRP3QmHTLuTtqU1t","authorship_tag":"ABX9TyNeDbexuqzYaZVoADlT3z75"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"048a9993dc7f4bb1bf962587aeced61a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6233f604186541b8b4fee1a528d0c76b","placeholder":"​","style":"IPY_MODEL_cbe6abf372c64e2ba975888d3b163ba4","value":"Downloading: 100%"}},"04c762177b33444ab16cc51d2b1f08c9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"063ee31f819e4bfdb4a5b99897bda37e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"10f4b5559ab44974a2b76afd8883c2e8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b3ab885b70b541ab9ba05a3e73fea16f","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_55b5dcfdb21e417fa79131332fb062bc","value":28}},"12fa01696c7b4146828bd1d2fc5d65c2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9357739c008d41ebbb9c2b9468061405","IPY_MODEL_9b834fafb7904e3f9faa28952852d066","IPY_MODEL_1bf0d0f3c9964aeca517449dbfbe8f46"],"layout":"IPY_MODEL_537d8c701b4543b3ab45500f100e1b34"}},"1bf0d0f3c9964aeca517449dbfbe8f46":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_65fcc9087db04bd4be3c9f22800721c8","placeholder":"​","style":"IPY_MODEL_d748e769064b4c80b71d4ca246c9502e","value":" 455k/455k [00:00&lt;00:00, 618kB/s]"}},"1d173e688bd54e888e3ad1824cfd3df0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"280f1e4471964b1abad6fe9408c58d63":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2b218c33cffe430ebb20d9194caab514":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2eda9fe5365d40a3a007495da6467736":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_048a9993dc7f4bb1bf962587aeced61a","IPY_MODEL_a21acaf5b9954b17aa6ffcf740859353","IPY_MODEL_e3488b85d8d246f49ef0f91dc8c892ae"],"layout":"IPY_MODEL_8addda51ca0a42ed8670d2b3d2b30113"}},"3e8a6782c3c94e579d89ac2e0a4be65c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4230c72eb0474f3e937096eeb86b253a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"47582eb03c714d31a68a0bef22754120":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_88d276ebc8814112a18da7b025ae97af","placeholder":"​","style":"IPY_MODEL_5c359d5782e446ba8868b7efe5076e66","value":" 226k/226k [00:00&lt;00:00, 332kB/s]"}},"4921d37bcbf14127aff575e0d642daae":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b5f74b2090d34621ab53827b3a03c505","IPY_MODEL_57db02c3b106477c9bfd367699247644","IPY_MODEL_47582eb03c714d31a68a0bef22754120"],"layout":"IPY_MODEL_063ee31f819e4bfdb4a5b99897bda37e"}},"4bfa4b0141124e4290ebaced6a61a43c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"537d8c701b4543b3ab45500f100e1b34":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5440388945444d728060ea090cc04613":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"55b5dcfdb21e417fa79131332fb062bc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"57db02c3b106477c9bfd367699247644":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2b218c33cffe430ebb20d9194caab514","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4230c72eb0474f3e937096eeb86b253a","value":231508}},"5c359d5782e446ba8868b7efe5076e66":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5cf2f148ca414b3a8c0f0b35b6f8721a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6233f604186541b8b4fee1a528d0c76b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"65fcc9087db04bd4be3c9f22800721c8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b0947b0384f46f580d5f0b49ef02c56":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"81b03fd950f44a648b382107e17c9aa8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"88d276ebc8814112a18da7b025ae97af":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"89147d52186342a998836fa3ff23f20f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d75f702159ab4e78a357f7de1ae7c628","IPY_MODEL_10f4b5559ab44974a2b76afd8883c2e8","IPY_MODEL_c6d9181e20ef42ddbd779042cad07ef4"],"layout":"IPY_MODEL_c1991ad9f4d740f5b6aea099ceaf06c7"}},"8addda51ca0a42ed8670d2b3d2b30113":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9357739c008d41ebbb9c2b9468061405":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e8a6782c3c94e579d89ac2e0a4be65c","placeholder":"​","style":"IPY_MODEL_f4df98ce3bf543958a7d0075c79eaf17","value":"Downloading: 100%"}},"9b834fafb7904e3f9faa28952852d066":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_04c762177b33444ab16cc51d2b1f08c9","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6b0947b0384f46f580d5f0b49ef02c56","value":466062}},"a21acaf5b9954b17aa6ffcf740859353":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cdd0a42bc2d44d15a060bce6ec265882","max":483,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4bfa4b0141124e4290ebaced6a61a43c","value":483}},"b3ab885b70b541ab9ba05a3e73fea16f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5f74b2090d34621ab53827b3a03c505":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d173e688bd54e888e3ad1824cfd3df0","placeholder":"​","style":"IPY_MODEL_5cf2f148ca414b3a8c0f0b35b6f8721a","value":"Downloading: 100%"}},"bbe23adb72584c528a044540ad2fb986":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c1991ad9f4d740f5b6aea099ceaf06c7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6d9181e20ef42ddbd779042cad07ef4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cef7f46cf51d4397bbec8ad9e8391e59","placeholder":"​","style":"IPY_MODEL_bbe23adb72584c528a044540ad2fb986","value":" 28.0/28.0 [00:00&lt;00:00, 693B/s]"}},"cbe6abf372c64e2ba975888d3b163ba4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cdd0a42bc2d44d15a060bce6ec265882":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cef7f46cf51d4397bbec8ad9e8391e59":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d748e769064b4c80b71d4ca246c9502e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d75f702159ab4e78a357f7de1ae7c628":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fe11bc0d55de48e7a7450832291116bb","placeholder":"​","style":"IPY_MODEL_280f1e4471964b1abad6fe9408c58d63","value":"Downloading: 100%"}},"e3488b85d8d246f49ef0f91dc8c892ae":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_81b03fd950f44a648b382107e17c9aa8","placeholder":"​","style":"IPY_MODEL_5440388945444d728060ea090cc04613","value":" 483/483 [00:00&lt;00:00, 11.4kB/s]"}},"f4df98ce3bf543958a7d0075c79eaf17":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fe11bc0d55de48e7a7450832291116bb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}