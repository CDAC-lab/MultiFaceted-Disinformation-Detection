{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Classification using SOM.ipynb","provenance":[],"mount_file_id":"1OyGbMEasiXDC-mZ_WkwnM6QvfLAxUzdH","authorship_tag":"ABX9TyPBTCt3B4BabQM2MUv7AWyY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["! pip install minisom -q"],"metadata":{"id":"VYhMuzhDzY8w","executionInfo":{"status":"ok","timestamp":1647402286846,"user_tz":-330,"elapsed":3862,"user":{"displayName":"Srikandabala Kogul","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjJ7_wrqRECyV89KjY0M4usgytHh_ss4LSxI_aw3g=s64","userId":"12354510259357034369"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["# **1) IMPORTING LIBRARIES AND DEFINING FUNCTIONS**\n","\n","<ins>**Functions**</ins>\n","<br>\n","<br>\n","The following table defines and describes the functions used throughout this notebook.\n","<br>\n","<br>\n","\n","\\begin{array}{|c|c|} \\hline\n","\\textbf{Function} & \\textbf{Description} \\\\ \\hline\n","\\textbf{Convert Label} & Converts\\hspace{0.15cm}all\\hspace{0.15cm}types\\hspace{0.15cm}of\\hspace{0.15cm}true\\hspace{0.15cm}news\\hspace{0.15cm}to\\hspace{0.15cm}0\\hspace{0.15cm}and\\hspace{0.15cm}fake\\hspace{0.15cm}to\\hspace{0.15cm}1\\hspace{0.15cm} \\\\ \\hline\n","\\textbf{Get Fake Score, Get True Score} & Get\\hspace{0.15cm}respective\\hspace{0.15cm}scores\\hspace{0.15cm}from\\hspace{0.15cm}array \\\\ \\hline\n","\\textbf{Get Scaler} & Returns\\hspace{0.15cm}the\\hspace{0.15cm}scaler\\hspace{0.15cm}object\\hspace{0.15cm}to\\hspace{0.15cm}transform\\hspace{0.15cm}data \\\\  \\hline\n","\\textbf{Get All Data} &  \\\\ \\hline\n","\\textbf{Evaluate Model} & Given\\hspace{0.15cm}data\\hspace{0.15cm}and\\hspace{0.15cm}model\\hspace{0.15cm}returns\\hspace{0.15cm}accuracy,\\hspace{0.15cm}f1,\\hspace{0.15cm}recall\\hspace{0.15cm}and\\hspace{0.15cm}precision \\\\ \\hline\n","\\textbf{Get Dataset} & Given\\hspace{0.15cm}dataset\\hspace{0.15cm}name\\hspace{0.15cm}returns\\hspace{0.15cm}X\\_train,\\hspace{0.15cm}y\\_train,\\hspace{0.15cm}X\\_test\\hspace{0.15cm}and\\hspace{0.15cm}y\\_test \\\\ \\hline\n","\\textbf{Get Dataset One vs Rest} & Given\\hspace{0.15cm}dataset\\hspace{0.15cm}name\\hspace{0.15cm}returns\\hspace{0.15cm}X\\_train\\hspace{0.15cm}and\\hspace{0.15cm}y\\_train\\hspace{0.15cm}from\\hspace{0.15cm}it\\hspace{0.15cm}and\\hspace{0.15cm}X\\_test\\hspace{0.15cm}and\\hspace{0.15cm}y\\_test\\hspace{0.15cm}from\\hspace{0.15cm}the\\hspace{0.15cm}rest\\hspace{0.15cm} \\\\ \\hline\n","\\end{array}\n","\n","<br>"],"metadata":{"id":"2BeYbI_IbZz4"}},{"cell_type":"code","source":["# ============================================================================================================================================= #\n","LANGUAGE_FEATURES = [\"fake_score_occ\", \"true_score_occ\", \"fake_score_doc\", \"true_score_doc\", \"embd_true\",\"embd_fake\"]\n","EMOTION_FEATURES  = [\"anger\", \"anticipation\", \"disgust\", \"fear\", \"joy\", \"sadness\", \"surprise\", \"trust\"]\n","SEMANTIC_FEATURES = ['words_per_sentence', 'characters_per_word', 'punctuations_per_sentence', 'get_sentiment_polarity', \n","                    'lexical_diversity', 'content_word_diversity', 'redundancy', 'noun', 'verb', 'adj', 'adv', \"qn_symbol_per_sentence\", \n","                    \"num_exclamation_per_sentence\", \"url_count_per_sentence\"]\n","\n","ALL_FEATURES = EMOTION_FEATURES + LANGUAGE_FEATURES + SEMANTIC_FEATURES\n","# ============================================================================================================================================= #\n","from minisom import MiniSom\n","import gc\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.preprocessing import PowerTransformer\n","from sklearn.preprocessing import RobustScaler\n","from sklearn.preprocessing import QuantileTransformer\n","from sklearn.preprocessing import Normalizer\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","rng = np.random.RandomState(42)\n","import pandas as pd\n","from google.colab import data_table\n","data_table.enable_dataframe_formatter()\n","import pickle\n","# ============================================================================================================================================= #\n","def convert_label(label):\n","\n","  if label in ['true', 'mostly-true', 'half-true', 'real', 'Real', 0, 'REAL']:\n","    return 0\n","\n","  if label in ['false', 'pants-fire', 'barely-true', 'fake', 'Fake', 1, 'FAKE']:\n","    return 1\n","# ============================================================================================================================================= #\n","def get_fake_score(scores):\n","  return float(scores.strip(\"[]\").split(\",\")[0].strip())\n","\n","def get_true_score(scores):\n","  return float(scores.strip(\"[]\").split(\",\")[1].strip())\n","\n","def get_fake_score_occ(scores):\n","  return float(scores.strip(\"[]\").split(\",\")[2].strip())\n","\n","def get_fake_score_doc(scores):\n","  return float(scores.strip(\"[]\").split(\",\")[3].strip())\n","\n","def get_true_score_occ(scores):\n","  return float(scores.strip(\"[]\").split(\",\")[4].strip())\n","\n","def get_true_score_doc(scores):\n","  return float(scores.strip(\"[]\").split(\",\")[5].strip())\n","# ============================================================================================================================================= #\n","def get_dataset_test(dataset_name, data):\n","  \n","  df = data[dataset_name][\"combined_dataframe\"]\n","  test_split_available = False\n","\n","  try:\n","    df_test = df.loc[df['split'] == 'test']\n","    test_split_available = True\n","\n","  except KeyError:\n","    pass\n","\n","  if(test_split_available):\n","\n","    X, y = df_test[ALL_FEATURES].to_numpy(), df_test['label'].to_numpy()\n","\n","  else:\n","\n","    X, y = df[ALL_FEATURES].to_numpy(), df['label'].to_numpy()\n","\n","  return X, y\n","# ============================================================================================================================================= #\n","def get_dataset_all(dataset_name, data):\n","\n","  df = data[dataset_name][\"combined_dataframe\"]\n","\n","  X = df[ALL_FEATURES].to_numpy()\n","\n","  y = df['label'].to_numpy()\n","\n","  return X, y\n","# ============================================================================================================================================= #\n","def shape_outliers(dataFrame, features):\n","\n","  dataframe = dataFrame.copy(deep=True)\n","\n","  for column in dataframe[features].columns.tolist():\n","\n","    Q1 = dataframe[column].quantile(0.25)\n","    Q3 = dataframe[column].quantile(0.75)\n","    \n","    IQR = (Q3 - Q1)\n","    minV = Q1 - 1.5*IQR\n","    maxV = Q3 + 1.5*IQR\n","    \n","    temp = dataframe[column].copy()\n","\n","    if ( column not in [\"qn_symbol_per_sentence\" , \"num_exclamation_per_sentence\" ,\"lexical_diversity\" ,\"url_count_per_sentence\"] ) :\n","      dataframe[column]=dataframe[column].apply(lambda x:minV if x< minV else maxV if x>maxV else x)\n","\n","      mean = dataframe[column].mean()\n","      std  = dataframe[column].std() \n","\n","      dataframe[column]=dataframe[column].apply(lambda x: (x-mean)/std )\n","      \n","    else:\n","      dataframe[column]=dataframe[column].apply(lambda x : 1 if x>0 else 0)\n","    \n","  return dataframe\n","# ============================================================================================================================================= #"],"metadata":{"id":"I9ohG7VIN3bG","executionInfo":{"status":"ok","timestamp":1647402677114,"user_tz":-330,"elapsed":517,"user":{"displayName":"Srikandabala Kogul","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjJ7_wrqRECyV89KjY0M4usgytHh_ss4LSxI_aw3g=s64","userId":"12354510259357034369"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["# **2) IMPORTING DATASETS**\n","\n","<ins>**Datasets Used**</ins>\n","<br>\n","<br>\n","\\begin{array}{|c|c|} \\hline\n","\\textbf{Dataset} & \\textbf{Description} & \\textbf{No. True} & \\textbf{No. Fake}  \\\\ \\hline \\hline\n","\\textbf{LIAR} & News\\hspace{0.15cm}from\\hspace{0.15cm}Politifact & foo & bar \\\\ \\hline\n","\\textbf{CodaLab} & COVID\\hspace{0.15cm}Tweets & foo & bar \\\\ \\hline\n","\\textbf{FakeNewsNet} & Politifact\\hspace{0.15cm}and\\hspace{0.15cm}GossipCop & foo & bar \\\\  \\hline\n","\\textbf{Kaggle} & bar & foo & bar \\\\ \\hline\n","\\textbf{ISOT} & Long\\hspace{0.15cm}text & foo & bar \\\\ \\hline\n","\\end{array}\n","\n","<br>"],"metadata":{"id":"-nl0p2ZXbief"}},{"cell_type":"code","execution_count":21,"metadata":{"id":"BE-75y8HNrOw","executionInfo":{"status":"ok","timestamp":1647402679442,"user_tz":-330,"elapsed":92,"user":{"displayName":"Srikandabala Kogul","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjJ7_wrqRECyV89KjY0M4usgytHh_ss4LSxI_aw3g=s64","userId":"12354510259357034369"}}},"outputs":[],"source":["datasets = {\n","\n","    \"ISOT\" : {\n","        \"emotion_file_path\" : r\"/content/drive/Shareddrives/[FYP] Fake News Detection/Results/ISOT/ISOT_emotion_scores_modified.csv\",\n","        \"lexicon_file_path\" : r\"/content/drive/Shareddrives/[FYP] Fake News Detection/Results/ISOT/ISOT_with_WELFAKE_Lexicon_Scores_Modified.csv\",\n","        \"semantic_file_path\" : r\"/content/drive/Shareddrives/[FYP] Fake News Detection/Results/ISOT/ISOT_sementic.csv\",\n","        \"embedding_file_path\" : r\"/content/drive/Shareddrives/[FYP] Fake News Detection/Results/Final/ISOT/ISOT_embedding_new.csv\"\n","    },\n","\n","    \"FA-KES\" : {\n","        \"emotion_file_path\" : r\"/content/drive/Shareddrives/[FYP] Fake News Detection/Datasets/FA-KES/FA-KES_emotion_scores_modified.csv\",\n","        \"lexicon_file_path\" : r\"/content/drive/Shareddrives/[FYP] Fake News Detection/Datasets/FA-KES/FA-KES_with_WELFAKE_Lexicon_Scores_Modified.csv\",\n","        \"semantic_file_path\" : r\"/content/drive/Shareddrives/[FYP] Fake News Detection/Results/FA-KES/FA-KES_sementic.csv\",\n","        \"embedding_file_path\" : r\"/content/drive/Shareddrives/[FYP] Fake News Detection/Results/Final/FA-KES/FA-KES_embedding_new.csv\" \n","    }\n","    \n","}"]},{"cell_type":"code","source":["for d in datasets:\n","  \n","  print(\"=========================\")\n","  print(\"Reading {}\".format(d))\n","  print(\"=========================\\n\")\n","  \n","  datasets[d][\"lexicon_dataframe\"] = pd.read_csv(datasets[d][\"lexicon_file_path\"]) \n","  datasets[d][\"emotion_dataframe\"] = pd.read_csv(datasets[d][\"emotion_file_path\"]) \n","  datasets[d][\"semantic_dataframe\"] = pd.read_csv(datasets[d][\"semantic_file_path\"])\n","  datasets[d][\"embedding_dataframe\"] = pd.read_csv(datasets[d][\"embedding_file_path\"])\n","\n","  id = {\"CodaLab\":\"id\", \"FakeNewsNet\":\"id_1\", \"ISOT\":\"id\", \"Kaggle_real_fake\":\"id\", \"LIAR\":\"ID\", \"FA-KES\":\"unit_id\"}\n","  ID = id[d]\n","\n","  df = datasets[d][\"emotion_dataframe\"].merge(datasets[d][\"semantic_dataframe\"], how='inner', on=ID,suffixes=('_Sentiment', '_Semantic'))\n","  df = df.merge(datasets[d][\"lexicon_dataframe\"], how='inner', on = ID,suffixes=('', '_Lexicon'))\n","  df = df.merge(datasets[d][\"embedding_dataframe\"], how='inner', on = ID,suffixes=('', '_Embedding'))\n","\n","  df[\"fake_score_occ\"], df[\"true_score_occ\"] = df[\"scores\"].apply(get_fake_score_occ), df[\"scores\"].apply(get_true_score_occ)\n","  df[\"fake_score_doc\"], df[\"true_score_doc\"] = df[\"scores\"].apply(get_fake_score_doc), df[\"scores\"].apply(get_true_score_doc)\n","\n","  df = df.loc[df[\"lang\"]==\"en\"].copy(deep=True)\n","\n","  df[\"label\"] = df[\"label\"].apply(convert_label)\n","  \n","  df = shape_outliers(df, SEMANTIC_FEATURES + EMOTION_FEATURES)\n","\n","  ALL = ALL_FEATURES.copy()\n","  ALL.append(\"label\")\n","\n","  ALL_WITH_SPLIT = ALL.copy()\n","  ALL_WITH_SPLIT.append(\"split\")\n","\n","  try:\n","\n","    datasets[d][\"combined_dataframe\"] = df[ALL_WITH_SPLIT]\n","\n","  except KeyError:\n","\n","    datasets[d][\"combined_dataframe\"] = df[ALL]\n","\n","  print(\"Total number of datapoints : {}\".format(len(df)))\n","\n","  del df\n","  del datasets[d][\"lexicon_dataframe\"]\n","  del datasets[d][\"emotion_dataframe\"]\n","  del datasets[d][\"semantic_dataframe\"] \n","  del datasets[d][\"embedding_dataframe\"]\n","\n","  gc.collect()\n","\n","  print(\"\\nDone !!!\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HX8MZV3BN6QB","executionInfo":{"status":"ok","timestamp":1647402713987,"user_tz":-330,"elapsed":34635,"user":{"displayName":"Srikandabala Kogul","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjJ7_wrqRECyV89KjY0M4usgytHh_ss4LSxI_aw3g=s64","userId":"12354510259357034369"}},"outputId":"72e59f5d-d718-41b1-cc1b-c04cdff54f6a"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["=========================\n","Reading ISOT\n","=========================\n","\n","Total number of datapoints : 44140\n","\n","Done !!!\n","\n","=========================\n","Reading FA-KES\n","=========================\n","\n","Total number of datapoints : 789\n","\n","Done !!!\n","\n"]}]},{"cell_type":"markdown","source":["# **3) RESULTS**"],"metadata":{"id":"nqAnq9gJbnq9"}},{"cell_type":"code","source":["def classify(som, data):\n","    \"\"\"Classifies each sample in data in one of the classes definited\n","    using the method labels_map.\n","    Returns a list of the same length of data where the i-th element\n","    is the class assigned to data[i].\n","    \"\"\"\n","    winmap = som.labels_map(X_train, y_train)\n","    default_class = np.sum(list(winmap.values())).most_common()[0][0]\n","    result = []\n","    for d in data:\n","        win_position = som.winner(d)\n","        if win_position in winmap:\n","            result.append(winmap[win_position].most_common()[0][0])\n","        else:\n","            result.append(default_class)\n","    return result"],"metadata":{"id":"omLWQA-31Z9X","executionInfo":{"status":"ok","timestamp":1647402856407,"user_tz":-330,"elapsed":533,"user":{"displayName":"Srikandabala Kogul","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjJ7_wrqRECyV89KjY0M4usgytHh_ss4LSxI_aw3g=s64","userId":"12354510259357034369"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import classification_report\n","from sklearn.model_selection import train_test_split\n","\n","X, y = get_dataset_all(\"FA-KES\", datasets)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify=y)\n","# X_test, y_test = get_dataset_test(\"FA-KES\", datasets)\n","\n","som = MiniSom(11, 11, 28, sigma=3, learning_rate=1, \n","              neighborhood_function='gaussian', activation_distance=\"cosine\")\n","\n","som.pca_weights_init(X_train)\n","som.train(X_train, 500, verbose=True)\n","\n","print(classification_report(y_test, classify(som, X_test)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cXfvQMAy1cVF","executionInfo":{"status":"ok","timestamp":1647403447559,"user_tz":-330,"elapsed":550,"user":{"displayName":"Srikandabala Kogul","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjJ7_wrqRECyV89KjY0M4usgytHh_ss4LSxI_aw3g=s64","userId":"12354510259357034369"}},"outputId":"1067161d-2a49-49e8-b6e2-19c94837f4d8"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":[" [ 500 / 500 ] 100% - 0:00:00 left \n"," quantization error: 3.485957442431342\n","              precision    recall  f1-score   support\n","\n","           0       0.57      0.58      0.58        84\n","           1       0.51      0.50      0.51        74\n","\n","    accuracy                           0.54       158\n","   macro avg       0.54      0.54      0.54       158\n","weighted avg       0.54      0.54      0.54       158\n","\n"]}]}]}